## 题外话

这一篇我不打算按照常规的方式进行总结，因为这一篇本身所涉及的内容更偏向于算法，而不是工程。所以，对于算法部分，我没法解读的很好。
但是，这一篇打动我的一点在于，他的内容其实给了我一些对于算法的启发。

## Bag of words

词袋模型是一种**统计方法**，通过词频对一篇文章进行representation.

- 维度是word个数，比如是 N.那么所有文章的vector size都是 N
- representation基于词频的表达。在确定单词全局唯一的顺序后，即下标确定。值就是词频。
- 对于query也可以映射到这个空间，可以做consine similariy

## TF-IDF

TF-IDF也是一种**统计方法**，用以评估一个词对于一个文件集或一个语料库中的其中一份文件的重要程度。其内部含义是：字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率反比下降。

所以，对于query/doc并没有统一的representation，而是直接计算tf-idf scores，这个也可以视作ranking score

这个也很好理解，如果一个word只存在于doc1当中，而不存在其余doc。那么显然这个word对于doc1很重要，这就是所谓的关键字。
但是，如果一个word在所有doc中存在的频率都很高，那么这个word对哪一个doc都不重要。比如功能词汇。相比于bag of words，tf-idf考虑了所有文章上下文信息。但是对于这个词本身的上下文，并没有考虑。

## Semantic Model

以上的办法在进行量化时，单纯的考虑了词频，而没有考虑到词义，比如有些word虽然不一样，但是语意是一样的。